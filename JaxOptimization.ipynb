{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazy1998/Solving-Optimization-Problems-with-JAX/blob/master/JaxOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YfAOPDZgJz0m"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-11-02 13:56:17.424944: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-11-02 13:56:17.691688: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2021-11-02 13:56:17.696932: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import jax.numpy as np\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "from jax import jacfwd, jacrev\n",
        "from jax.numpy import linalg\n",
        "\n",
        "from numpy import nanargmin,nanargmax \n",
        "\n",
        "key = random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2slwiA7gOe45"
      },
      "source": [
        "# Single Variable Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ebUpVGzwU8Eh"
      },
      "source": [
        "Defining the Object Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "REq_NrY5Nlvk"
      },
      "outputs": [
        {
          "ename": "Error",
          "evalue": "Session cannot generate requests",
          "output_type": "error",
          "traceback": [
            "Error: Session cannot generate requests",
            "at w.executeCodeCell (/home/raghurams/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
            "at w.execute (/home/raghurams/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
            "at w.start (/home/raghurams/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
            "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
            "at async t.CellExecutionQueue.executeQueuedCells (/home/raghurams/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
            "at async t.CellExecutionQueue.start (/home/raghurams/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
          ]
        }
      ],
      "source": [
        "def y(x):\n",
        "  return ((x * np.sqrt(12*x - 36 )) / (2*(x - 3)))\n",
        "def L(x):\n",
        "  return np.sqrt( x**2 + y(x)**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3cXxxCxVCWB"
      },
      "source": [
        "### Solving with Gradient Descent\n",
        "Using ***grad*** to find the derivative of the function ***L***\n",
        "\n",
        "Using ***vmap*** to map the ***minGD*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$x_{n+1} = x_{n} - 0.01 L^{'}(x_{n})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hdF8OOpMO0LS"
      },
      "outputs": [],
      "source": [
        "gradL = grad(L)\n",
        "\n",
        "def minGD(x): return x - 0.01 * gradL(x)\n",
        "\n",
        "domain = np.linspace(3.0, 5.0, num=50)\n",
        "\n",
        "vfuncGD = vmap(minGD)\n",
        "#Recurrent loop of gradient descent\n",
        "for epoch in range(500):\n",
        "  domain = vfuncGD(domain)\n",
        "\n",
        "minfunc = vmap(L)\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XL1-aMJ_M3t7"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "P8_NnP-xhvc1",
        "outputId": "f9be9ee0-e098-4ab0-dd40-8f93e8604c28"
      },
      "outputs": [],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the argmin is {}\".format(minimum,argmin))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6cWQtt4RShjZ"
      },
      "source": [
        "### Solving with Newton's Method\n",
        "Using ***grad*** to find the derivative of the function ***L***\n",
        "\n",
        "Using ***vmap*** to map the ***minGD*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$x_{n+1} = x_{n} - \\frac{L^{'}(x_{n})}{L^{''}(x_{n})} $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cSWJsxTAkKvl"
      },
      "outputs": [],
      "source": [
        "gradL = grad(L)\n",
        "gradL2 = grad(gradL)\n",
        "\n",
        "def minNewton(x): return x - gradL(x)/gradL2(x)\n",
        "\n",
        "domain = np.linspace(3.0, 5.0, num=50)\n",
        "vfuncNT = vmap(minNewton)\n",
        "for epoch in range(50):\n",
        "  domain = vfuncNT(domain)\n",
        "\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mw_BEFd8Tz19"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "8FQhAYifzQs8",
        "outputId": "73f4c934-8092-4488-bbf3-8876a1350dc7"
      },
      "outputs": [],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the argmin is {}\".format(minimum,argmin))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "babrapVGOsNB"
      },
      "source": [
        "# Multivariable Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sKTRywtlUE_s"
      },
      "source": [
        "Defining the Object Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bNXOUzoQzqW-"
      },
      "outputs": [],
      "source": [
        "def paraboloid(x): return (x[0]*x[1]-2)**2 + (x[1]-3)**2\n",
        "minfunc = vmap(paraboloid)\n",
        "\n",
        "J = jacfwd(paraboloid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZfP3qpIUZwj"
      },
      "source": [
        "### Solving with Gradient Descent using the Jacobian ($\\nabla f$)\n",
        "Using ***grad*** to find the jacobian of the function ***paraboloid***\n",
        "\n",
        "Using ***vmap*** to map the ***minJacobian*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$X_{n+1} = X_{n} - 0.01\\nabla f(X_{n}) $\n",
        "\n",
        "Where $ X = \\left[x_1,x_2,\\ldots,x_n \\right]^T$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FT4zkldxoIZX"
      },
      "outputs": [],
      "source": [
        "def minJacobian(x): return x - 0.1*J(x)  \n",
        "\n",
        "domain = random.uniform(key, shape=(50,2), dtype='float32',\n",
        "                        minval=-5.0, maxval=5.0)\n",
        "\n",
        "vfuncHS = vmap(minJacobian)\n",
        "for epoch in range(150):\n",
        "  domain = vfuncHS(domain)\n",
        "\n",
        "\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MXFPZRIoZAiT"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "6eNf0cj_w3hJ",
        "outputId": "3c2c3172-4793-4f43-d7ba-0aebff4358d6"
      },
      "outputs": [],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the arg min is ({},{})\".format(minimum,argmin[0],argmin[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oUx3v1ysZRzd"
      },
      "source": [
        "Defining the Hessian as $\\nabla (\\nabla f) = \\nabla^{2}f$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7VUM43RM87dR"
      },
      "outputs": [],
      "source": [
        "def hessian(f):\n",
        "    return jacfwd(jacrev(f))\n",
        "    \n",
        "H = hessian(paraboloid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kxCf6SfdZ2hA"
      },
      "source": [
        "### Solving with Newton's Method using the Hessian ($\\nabla^{2} f$)\n",
        "Using ***hessian*** to find the Hessian of the function ***paraboloid***\n",
        "\n",
        "Using ***vmap*** to map the ***minHessian*** function over the ***domain***\n",
        "\n",
        "Using the gradient descent equation:\n",
        "\n",
        "$X_{n+1} = X_{n} - 0.1 H^{-1}(X_{n}) \\nabla f(X_{n}) $\n",
        "\n",
        "Where $ X = \\left[x_1,x_2,\\ldots,x_n \\right]^T$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TSb8zk0h9-Ju"
      },
      "outputs": [],
      "source": [
        "def minHessian(x): return x - 0.1*linalg.inv(H(x)) @ J(x)  \n",
        "\n",
        "\n",
        "domain = random.uniform(key, shape=(50,2), dtype='float32',\n",
        "                        minval=-5.0, maxval=5.0)\n",
        "\n",
        "vfuncHS = vmap(minHessian)\n",
        "for epoch in range(150):\n",
        "  domain = vfuncHS(domain)\n",
        "\n",
        "\n",
        "minimums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ErsWvrRybaBe"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "T_N1J8l_-8mN",
        "outputId": "df952ffe-10d2-44e2-fb35-2beb62b6244a"
      },
      "outputs": [],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {} the arg min is ({},{})\".format(minimum,argmin[0],argmin[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FTw8u2VfO2nZ"
      },
      "source": [
        "# Multivariable Constrained Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uj12ffIludMv"
      },
      "source": [
        "Defining the Object Function $f(x)$\n",
        "and The Constrained Function $g(x)$\n",
        "\n",
        "The Lagrangian is defined as ***Lagrange*** $f(x) - \\lambda g(x) = 0 $\n",
        "\n",
        "Therefore using Newton's Method we solve for $Lagrange(x)=0$\n",
        "\n",
        "Which is the same as minimizing the multivariable function $\\nabla Lagrange(x)$\n",
        "\n",
        "Thus the reccurent loop is:\n",
        "$X_{n+1} = X_{n} - \\nabla^{2} Lagrange^{-1}(X_{n}) \\nabla Lagrange(X_{n}) $\n",
        "\n",
        "Where $ X = \\left[x_1,x_2,\\ldots,x_n \\right]^T$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SIl0XEFQQmGk"
      },
      "outputs": [],
      "source": [
        "def f(x): return 4*(x[0]**2)*x[1]\n",
        "def g(x): return x[0]**2 + x[1]**2 - 3\n",
        "\n",
        "minfunc = vmap(f)\n",
        "\n",
        "def Lagrange(l): return f(l[0:2]) - l[3]*g(l[0:2])\n",
        "\n",
        "L = jacfwd(Lagrange)\n",
        "gradL = jacfwd(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QFR44_jUT0c2"
      },
      "outputs": [],
      "source": [
        "def solveLagrangian(l): return l - linalg.inv(gradL(l)) @ L(l)  \n",
        "\n",
        "\n",
        "domain = random.uniform(key, shape=(50,3), dtype='float32',\n",
        "                        minval=-5.0, maxval=5.0)\n",
        "\n",
        "vfuncsLAG = vmap(solveLagrangian)\n",
        "for epoch in range(150):\n",
        "  domain = vfuncsLAG(domain)\n",
        "\n",
        "minimums = minfunc(domain)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MHHGrgWyxiZk"
      },
      "source": [
        "Finding the argmin and the objective minimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "p8ZwO0A8l-PU",
        "outputId": "56f93c06-b239-4c20-bb45-3f6a0a38b18d"
      },
      "outputs": [],
      "source": [
        "arglist = nanargmin(minimums)\n",
        "argmin = domain[arglist]\n",
        "minimum = minimums[arglist]\n",
        "\n",
        "print(\"The minimum is {}, the arg min is ({},{}), the lagrangian is {}\".format(minimum,argmin[0],argmin[1],argmin[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pQizl0Pi2Vm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GG8vL7Jd1GPU"
      },
      "source": [
        "# Solving a Three Variable Multivariable Constrained Optimization\n",
        "\n",
        "Find the dimensions of the box with largest volume if the total surface area is $64 cm^2$\n",
        "\n",
        "$Volume = f(x_0,x_1,x_2) = x_0 x_1x_2$\n",
        "\n",
        "$Surface Area = g(x_0,x_1,x_2) = 2x_0x_1 + 2x_1x_1 + 2x_0x_2 = 64$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YdcKTxCE1MAv"
      },
      "outputs": [],
      "source": [
        "def f(x): return x[0]*x[1]*x[2]\n",
        "def g(x): return 2*x[0]*x[1] + 2*x[1]*x[2] + 2*x[0]*x[2] - 64\n",
        "\n",
        "minfunc = vmap(f)\n",
        "\n",
        "def Lagrange(l): return f(l[0:3]) - l[3]*g(l[0:3])\n",
        "\n",
        "L = jacfwd(Lagrange)\n",
        "gradL = jacfwd(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QU-U0Z4W2WOg"
      },
      "outputs": [],
      "source": [
        "def solveLagrangian(l): return l - 0.1*linalg.inv(gradL(l)) @ L(l)  \n",
        "\n",
        "domain = random.uniform(key, shape=(50,4), dtype='float32',\n",
        "                        minval=0, maxval=10)\n",
        "\n",
        "vfuncsLAG = vmap(solveLagrangian)\n",
        "for epoch in range(200):\n",
        "  domain = vfuncsLAG(domain)\n",
        "\n",
        "\n",
        "maximums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "dDS7U7dw2ZjM",
        "outputId": "cd0568d1-b29b-485e-e3c7-4edbcc485f3f"
      },
      "outputs": [],
      "source": [
        "arglist = nanargmax(maximums)\n",
        "argmin = domain[arglist]\n",
        "minimum = maximums[arglist]\n",
        "\n",
        "print(\"The minimum is {}, the argmin is ({},{},{}), the lagrangian is {}\".format(minimum,argmin[0],\n",
        "                                                                                         argmin[1],\n",
        "                                                                                         argmin[2],\n",
        "                                                                                         argmin[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H8eWqfsmH0df"
      },
      "source": [
        "It should be noted that this gives a 0.0000118855014% error!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IvMt89tBEoTB"
      },
      "source": [
        "# Multivariable MultiConstrained Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a-F_k9fcM8pd"
      },
      "source": [
        "Let's start by trying to maximize the object function $f(x_0,x_1)$ with the constraints $g(x_0,x_1)$ and $h(x_0,x_1)$. \n",
        "\n",
        "$f(x_0,x_1) = 13x_0*2 + 10x_0x_1+ 7x_1^2 + x_0 + x_1 +2$\n",
        "\n",
        "$g(x_0,x_1) = 2x_0 - 5x_1 - 2 $\n",
        "\n",
        "$h(x_0,x_1) = x_0 + x_1 -1$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TAfygBNrEpk0"
      },
      "outputs": [],
      "source": [
        "def f(x) : return 13*x[0]**2 + 10*x[0]*x[1] + 7*x[1]**2 + x[0] + x[1]\n",
        "def g(x) : return 2*x[0]-5*x[1]-2\n",
        "def h(x) : return x[0] + x[1] -1\n",
        "\n",
        "minfunc = vmap(f)\n",
        "\n",
        "def Lagrange(l): return f(l[0:2]) - l[2]*g(l[0:2]) - l[3]*h(l[0:2])\n",
        "\n",
        "L = jacfwd(Lagrange)\n",
        "gradL = jacfwd(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QJGFo_9BNm7D"
      },
      "outputs": [],
      "source": [
        "def solveLagrangian(l): return l - 0.1*linalg.inv(gradL(l)) @ L(l)  \n",
        "\n",
        "\n",
        "domain = random.uniform(key, shape=(300,4), dtype='float32',\n",
        "                        minval=-4, maxval=1)\n",
        "\n",
        "\n",
        "vfuncsLAG = vmap(solveLagrangian)\n",
        "for epoch in range(300):\n",
        "  domain = vfuncsLAG(domain)\n",
        "\n",
        "\n",
        "maximums = minfunc(domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "DFhcdCiNN7eX",
        "outputId": "76907cff-3055-46f4-9863-64ffd7e6e8a3"
      },
      "outputs": [],
      "source": [
        "arglist = nanargmin(maximums)\n",
        "argmin = domain[arglist]\n",
        "minimum = maximums[arglist]\n",
        "\n",
        "print(\"The minimum is {}, the argmin is ({},{}), the lagrangians are {} and {}\".format(minimum,argmin[0],\n",
        "                                                                                         argmin[1],\n",
        "                                                                                         argmin[2],\n",
        "                                                                                         argmin[3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4XSvBlIrstyV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyNnP0VFlaJ8gdipP2iXhWR0",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "JaxOptimization.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5b83cc4dcdb05926a415d6e0f5646a1b0e766089034cc677a2b6a2f3645e1dd2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
